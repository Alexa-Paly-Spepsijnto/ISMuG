# Novel AI Music Generation

Given the output of our human state detection model (which would be one of [anxious, exuberant, depressed, content]), we plan to generate novel music that matches the provided state. 

Our plan is as follows: 
- curate n different datasets (n = # of human state classifications possible with our human state detection model, i.e. 4)
- each dataset will contain chord progressions with labels for the corresponding human state
- eventually, chord progressions will be random permutations of chords based on a probability distribution (markov chains and gibbs sampling)
- chord progressions will be fed into magenta's improv_rnn to generate a melody line that matches the provided backing chords
- a more complex melody line can be generated by feeding the output of improv_rnn as input to performance_rnn, which will account for things like tempo, volume, etc
- re-combining the melodic output of performance_rnn with the backing chords from improv_rnn will result in a "full song" that should maintain the originally labeled "mood" of the initially fed-in chord progression
